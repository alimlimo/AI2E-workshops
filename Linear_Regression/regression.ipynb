{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/cover.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI2E - [Workshop 3] - [Introduction to ML]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand and perform linear regression on datasets with different number of features.  \n",
    "  \n",
    "<h3>Content</h3> \n",
    "<ol>\n",
    "    <li>Linear Regression with one feature.</li>  \n",
    "    <li>Linear Regression with two features.</li>  \n",
    "    <li>Linear Regression with three features.</li>  \n",
    "    <li>Standard Normalization.</li>  \n",
    "    <li>Regularization.</li>  \n",
    "    <li>Conclusion</li>\n",
    "</ol>    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. Linear Regression with One Feature</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from numpy.linalg import inv \n",
    "from mpl_toolkits.mplot3d import Axes3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and print the data\n",
    "#plot the variables\n",
    "df = pd.read_csv('csv/1.csv')\n",
    "print(df.head())\n",
    "plt.scatter(df['taille'],df['poid'])\n",
    "plt.xlabel('taille')\n",
    "plt.ylabel('poid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computer the estimator\n",
    "df['const'] = 1 \n",
    "X = df[['taille','const']]\n",
    "y = df['poid']\n",
    "estim = np.dot(np.dot(inv(np.dot(X.transpose(),X)),X.transpose()),y)\n",
    "print(estim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot the line \n",
    "plt.scatter(df['taille'],df['poid'])\n",
    "plt.plot(df['taille'],np.dot(df[['taille','const']].values,estim),c='orange')\n",
    "plt.scatter(1.63,np.dot([1.63,1],estim),c='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Linear Regression with Two Features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#read and print the data \n",
    "#plot the data\n",
    "df = pd.read_csv('csv/2.csv')\n",
    "print(df.head())\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(df['superficie'], df['region'], df['prix'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#compute the estimator\n",
    "z = df['prix'].values\n",
    "df['const'] = 1 \n",
    "X = df[['superficie','region','const']].values\n",
    "estim = np.dot(np.dot(inv(np.dot(X.transpose(),X)),X.transpose()),z)\n",
    "print(estim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the plan\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(df['superficie'], df['region'], df['prix'])\n",
    "ax.plot_trisurf(df['superficie'],df['region'],np.dot(X,estim),cmap='GnBu',antialiased=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3. Linear Regression with Three features</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/3.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3)\n",
    "fig.tight_layout(pad=3.0)\n",
    "for i,v in enumerate(['x','y','z']):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.scatter(df[v],df['d'])\n",
    "    plt.xlabel(v)\n",
    "    plt.ylabel('d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['const'] = 1 \n",
    "X = df[['x','y','z','const']].values \n",
    "estim = np.dot(np.dot(inv(np.dot(X.transpose(),X)),X.transpose()),df['d'])\n",
    "print(estim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4. Standard Normalization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#normalize the data \n",
    "df[['x','y','z']] = (df[['x','y','z']] - df[['x','y','z']].mean() ) /df[['x','y','z']].std()\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5. Regularization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computer the estimator with regularization\n",
    "X = df[['x','y','z','const']].values \n",
    "lambd=5\n",
    "estim = np.dot(np.dot(inv(np.dot(X.transpose(),X) + lambd*np.identity(4)),X.transpose()),df['d'])\n",
    "print(estim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(df['x'],df['d'])\n",
    "plt.plot(df['x'],estim[0]*df['x']+estim[-1],color='orange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>6. Conclusion</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression can approximate linear relationship between the target and the features but in some situations it can overfit, we can then use regularization to prevent that.  \n",
    "In the next lesson you will learn how to use Logistique Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
